\chapter{INTRODUCTION}\label{introducao}
\section{Contextualization}
A 3-dimensional (3D) representation of cities became a common term in the last decade \cite{demir2012}. What was once considered an alternative for visualization and entertainment, has become a powerful instrument of urban planning \cite{kolbe2009, stoter2011}. The technology is now well-known in most of the countries on the European continent, such as Switzerland \cite{swisstopo2010}, England \cite{accucities, vertex}, and Germany \cite{virtualcities, aringer2014, kruger2012, dollner2006}, also being commercially popular in North America, where many leading companies and precursor institutions reside. However, the semantic 3D mapping with features and applicability that go beyond the visual scope, is still considered a novelty in many other countries. In Brazil, according to the present study (see Section \ref{map-brazil}), the use of volumetric information as a resource for strategic and management planning is reduced in few cities.

According to a recent survey \cite{biljecki2015a}, approximately thirty real applications with the use of 3D urban models have been reported, ranging from environmental simulations, support of planning, cost reduction in modeling and decision making \cite{yang2016, truong2014}. Understanding the principles that establish the organization of such an environment, as well as its dynamics, requires a structural analysis between its objects and geometry \cite{lafarge2015}. Therefore, reproducing the maximum of its geometry and volume allows studies such as the estimation of solar irradiance on rooftops \cite{biljecki2015b}, as well as the determination of occluded areas \cite{eicker2015, jochem2009}, in analyzing hotspots for surveillance cameras \cite{yaagoubi2015}, Wi-Fi coverage \cite{lee2015}, in the urbanization and planning of green areas \cite{tooke2011, ahmad2003}, in evacuation plans in case of disasters \cite{kwan2005}, among others. 

Representing cities digitally exactly as they look like in the real world, was considered, for many years, mostly an entertainment application, rather than Cartography. With the appearance of LiDAR (Light Detection and Ranging) \cite{vosselman2001} and the Structure-from-Motion (SfM) and Multi-View Stereo (MVS) workflows \cite{snavely2006}, brought to real the structural urban mapping. Even though the data was extremely accurate, the surveys in mid-2010 were mostly made by airplanes, which fostered large-scale 3D reconstructions, in which buildings can be accurately represented with their rooftops, occupation, area, height or volume characteristics \cite{salehi2017}. With this remarkable stage, today, new branches of research try not faithfully represent the scene, but mitigate new ways to add knowledge to it, increasingly toward to semantic cities, where the nature of object is known and the relationship among them could easily be investigated.

In this sense, acquiring knowledge from remotely sensed data was always a permanent problem for the Computer Vision and Pattern Recognition community, which basically has the mission of interpreting huge amounts of data automatically. Until mid-2012, extracting any kind of information from images would require methodologies that would certainly not fully solve the problem, in many cases, only part of it. However, with the resurgence of Machine Learning (ML) technique in 2012 \cite{krizhevsky2012}, built on top of the original concept from 1989 \cite{lecun1989}, has changed the way to interpret images due its high accuracy and robustness on complex scenarios. The respectively ML concept called, Convolutional Neural Network (CNN), has enormous potential for interpretation, specially when dealing with large amount of data. In Remote Sensing, has also been successful used to detect urban objects \cite{zheng2015, segnet, teichmann2016} with high quality inferences.

But it was not always like this. During many years, the use of artificial neural models to solve complex problems such as automatic image classification was common, getting popular specially to adapt in complex situations with no human influences. Still, the methods or workflows available that time were too difficult to use considering the results it could provide, making its popularity lower in mid-2000. Recently, with new neural networks architectures, brought back the interest by autonomous classifiers, especially those for image classification. CNN has been a trend for pixelwise image segmentation, showing an extreme flexibility to detect and classify any kind of object even in scenarios where humans could not perceive.

Identifying simple facade features such as doors, windows, balconies, and roofs might be a tough task due to the infinite variations in shape, material compositions, and an unpredictable possibilities of occlusions. That means not only a good method would be required, but the addition of another variable, such as geometry, should be used to improve class separability. A new demand in the areas of Photogrammetry and Remote Sensing is leading the research to further analysis of these urban objects, in which takes advantage of the aforementioned optical campaigns, such as in \cite{bodis2017, hayko2014, teboul2011, gadde2017}, to acquire the object geometries on a low-cost and simple-to-use manner.

Urban environments used to have high spectral and spatial variability, because they are dynamic scenarios, which means that not only the presence of cars, vegetation, vehicles and pedestrians are aggravating the extraction of information, but also the constant actions of man on urban elements. But not all cities are that complex. One city could present a better geometry when compared to another in terms of architectural styles. In addition, suburbs use to have less traffic than city-centers, and that also affects the extraction. The term \textquotedblleft complex\textquotedblright$~$in this study refers to images where no preprocessing is performed, no cars are removed, no trees are cut off to benefit the imaging, no house or street was chosen beforehand, only images representing the perfect register of a real chaotic scenario were taken.

Considering these difficulties and the fact that today only a few experiments with complex scenarios have been carried out, a methodology using ground images\footnote{Also referenced here as street-side images.} is used, since they can provide all the facade details that aerial imagery might not be able to \cite{musialski2013}. The purpose here, is to delineate interest regions of facade images and assign each of them to a particular semantic label: roof, wall, window, balcony, door, and shop. Right after, these segmented features are used to link them onto their respective geometries. In order to detect these features, 6 datasets with distinct architectural styles are used as training samples to a CNN model. Once trained, the artificial knowledge generated for each dataset is tested to an unknown scene in Brazil. The facade geometry is then extracted through the use of a SfM/MVS pipeline, which is finally labeled by ray-tracing analysis according to each segmented image.

Based on this workflow, in Section \ref{chapter2} it is highlighted the essential urban characteristics for the extraction of information through remote sensing, its challenges and the evolution of techniques. In Section \ref{chapter3}, the details of the methodology and data adopted for the study are presented. In Section \ref{chapter4}, it is analyzed the results in both categories: on 2 (quality of detection) and 3-dimensions (quality of 3D labeling), as well as the training effects between the architectural style and the inference quality under an unknown one. Finally, in Section \ref{chapter5}, our main conclusions and future prospects.

\section{Hypotheses}
This work is based on the following hypotheses:    
\begin{itemize}      
    \item Facade features such as roof, windows, balconies, wall and doors can be automacally extracted even under complex scenarios and the non-necessity to pre-process the images;
    
    %\item The volumetric building precision is expressively better when extracted under datasets with high level details. 
    %\item A extração de detalhes das edificações são passíveis de análises completas quando adequadamente inseridas em contextos cartográficos válidos; % se eu não for abordar o citygml parsing, essa hipótese deve ser retirada
    %\item Details of facades can be analyzed by (i) sensors on close-range platforms, such as mobile UAVs (fixed or dynamic wings) and terrestrial (fixed or mobile); and (ii) long/medium-range, as airplanes, since it can carry sensors with specific acquisition capability and geometry (e.g. oblique cameras);
    %\item The sequence of facade images, when properly acquired, allows 3D reconstruction and, consequently, the observation of their volumetry by the SfM/MVS technique, most of the time, with no cost;       
\end{itemize}

\section{Objectives}
\subsection{Main}
From structural data campaigns, the main objective of this research is to explore the extraction of geometric information of buildings, simultaneosly, automatically detect their facade features and, finally, relate both information in one single 3D labeled model.

\subsection{Specific}
\begin{enumerate}	
    \item Develop a routine to classify facade elements in 2-dimensional (2D) images using a CNN neural architecture;
    \item Using the same images, obtain the facade geometry using SfM/MVS;
    \item Evaluate the performance of the neural model for different urban scenarios and architectural styles;
    \item Evaluate a case study with a real application in Brazil, whose architecture differs from the datasets used during the neural model training;
    \item Classify the 3D model of the extracted facade using the images previously segmented in the 2D domain by the technique of \emph{Ray-Tracing}.    
\end{enumerate}
