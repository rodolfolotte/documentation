\chapter{INTRODUCTION}\label{introducao}
A 3-dimensional (3D) representation of cities became a common term in the last decade \cite{demir2012}. What was once considered an alternative for visualization and entertainment, has become a powerful instrument of urban planning \cite{kolbe2009, stoter2011}. The technology is now well-known in most of the countries on the European continent, such as Switzerland \cite{swisstopo2010}, England \cite{accucities, vertex}, and Germany \cite{virtualcities, aringer2014, kruger2012, dollner2006}, also being commercially popular in North America, where many leading companies and precursor institutions reside. However, the semantic 3D mapping with features and applicability that go beyond the visual scope, is still considered a novelty in many other countries. In Brazil, according to the present study (see Section \ref{map-brazil}), the use of volumetric information as a resource for strategic and management planning is reduced to few cities (see Table \ref{poll-answers}).

According to a recent survey \cite{biljecki2015a}, approximately thirty real applications with the use of 3D urban models have been reported, ranging from environmental simulations, support of planning, cost reduction in modeling and decision making \cite{yang2016, truong2014}. Understanding the principles that establish the organization of such environment, as well as its dynamism, requires a structural analysis between its objects and geometry \cite{lafarge2015}. Therefore, reproducing the maximum of its geometry and volume allows studies such as the estimation of solar irradiance on rooftops \cite{biljecki2015b}, as well as the determination of occluded areas \cite{eicker2015, jochem2009}, in analyzing hotspots for surveillance cameras \cite{yaagoubi2015}, Wi-Fi coverage \cite{lee2015}, in the urbanization and planning of green areas \cite{tooke2011, ahmad2003}, in evacuation plans in case of disasters \cite{kwan2005}, among others. 

Representing cities digitally exactly as they look like in the real world, was considered, for many years, mostly an entertainment application, rather than Cartography. With the appearance of LiDAR (Light Detection and Ranging) \cite{vosselman2001} and the Structure-from-Motion (SfM) and Multi-View Stereo (MVS) workflows \cite{snavely2006}, brought to real the structural urban mapping. Even though the data was extremely accurate, the campaigns in mid-2010 were mostly made by airplanes, which fostered large-scale 3D reconstructions, in which buildings can be accurately represented with their rooftops, occupation, area, height or volume characteristics \cite{salehi2017}. With this remarkable stage, today, new branches of research try not to faithfully represent the scene, but to add knowledge to it, increasingly toward semantic cities\footnote{The term \textquotedblleft semantic\textquotedblright, in this case, consists in the interpretation of a certain unknown information in something readable. Once this set of unknown infomation is interpreted, it could be confront to another set of interpreted information, studying their relationship and, then, make any kind of decision.}, where the nature of object is known and the relationship among them could be investigated.

In this sense, acquiring knowledge from remotely sensed data was always a permanent problem for Computer Vision and Pattern Recognition communities, which basically have the mission of interpreting huge amounts of data automatically. Until mid-2012, extracting any kind of information from images would require methodologies that would certainly not fully solve the problem, in many cases, only part of it. However, with the resurgence of Machine Learning (ML) technique in 2012 \cite{krizhevsky2012}, built on top of the original concept from 1989 \cite{lecun1989}, has changed the way to interpret images due its high accuracy and robustness on complex scenarios. The respectively ML concept called Convolutional Neural Network (CNN) has enormous potential for interpretation, specially when dealing with large amount of data. In Remote Sensing, has also been used to detect urban objects \cite{zheng2015, segnet, teichmann2016} with high quality inferences.

During many years, however, the use of artificial neural models to solve complex problems such as automatic image classification was common, getting popular specially to adapt in complex situations with no human interferences. Still, the methods or workflows available that time were too difficult to use considering the results it could provide, making its popularity lower in mid-2000. Recently, new neural networks architectures brought back the interest by autonomous classifiers, especially those for image classification. CNN has been a trend for pixelwise image segmentation, showing an extreme flexibility to detect and classify any kind of object even in scenarios where humans could not perceive.

Identifying simple facade features such as doors, windows, balconies, and roofs might be a tough task due to the infinite variations in shape, material compositions, and an unpredictable possibility of occlusions. That means not only a good method would be required, but the addition of another variable, such as geometry, should be used to improve class separability. A new demand in the areas of Photogrammetry and Remote Sensing is leading the research to further analysis of these urban objects, in which takes advantage of the aforementioned optical campaigns, such as in \citeonline{bodis2017, hayko2014, teboul2011, gadde2017}, to acquire the object geometries on a low-cost and simple-to-use manner, which is the use of common cameras and minimal knowledge for acquiring.

Urban environments used to have high spectral and spatial variability, because they are dynamic scenarios, which means that not only the presence of cars, vegetation, vehicles and pedestrians are aggravating the extraction of information, but also the constant actions of man on urban elements. But not all cities are that complex. One city could present a better geometry when compared to another in terms of architectural styles, for example, the streets of Manhattan (wide), in United States, and the streets of Hong Kong (narrow), in China. In addition, suburbs use to have less traffic than city-centers, and that also affects the extraction. The term \textquotedblleft complex\textquotedblright$~$in this study refers to images where no preprocessing is performed, no cars are removed, no trees are cut off to benefit the imaging, no house or street was chosen beforehand, only images representing the perfect register of a real chaotic scenario were taken.

Considering these difficulties and the fact that today only a few experiments with complex scenarios have been carried out, a methodology using ground images\footnote{Also referenced here as street-side images.} is used, since they can provide all the facade details that aerial imagery might not be able to \cite{musialski2013}. The purpose here, is to delineate interest regions of facade images and assign each of them to a particular semantic label: roof, wall, window, balcony, door, and shop. Right after, these features are used to associate them onto their respective geometries. In order to detect these features, 6 datasets with distinct architectural styles are used as training samples to a CNN model. Once trained, the artificial knowledge generated for each dataset is tested to an unknown scene in Brazil. The facade geometry is then extracted through the use of a SfM/MVS pipeline, which is finally labeled by ray-tracing analysis according to each segmented image.

\section{Hypotheses}
This work is based on the following hypotheses:    
\begin{itemize}      

    \item The volumetry of buildings, as well as their facade features (e.g. roof, windows, balconies, wall and doors), can be accurately extracted through optical images and SfM/MVS technique;           
    \item Facade features can be automatically detected with CNN even under complex scenarios with no preprocessing need;    
    \item The geometric quality of the 3D model, as well as the quality of the 3D labeling, is a direct function of the point cloud density;  
    \item The geometric quality point cloud by SfM/MVS technique depends on the camera parameter estimation, image spectral and spatial characteristics. Therefore, the targets geometry and texture are fundamental in the process of reconstruction and classification.          
\end{itemize}

\section{Objectives}
\subsection{Main}
From structural data campaigns (image-based point cloud, see Section \ref{aquisicao}), the main objective of this research is to explore the extraction of geometric information of buildings, simultaneously, to detect their facade features and, finally, relate both information in one single 3D labeled model.

\subsection{Specific}
\begin{enumerate}	
    \item Develop a routine to classify facade elements in 2-dimensional (2D) images using a CNN architecture;
    \item Using the same images, obtain the facade geometry using SfM/MVS;
    \item Evaluate the performance of the neural model for different urban scenarios and architectural styles;
    \item Evaluate a case study with an application in Brazil, whose architecture differs from the datasets used during the neural model training;
    \item Classify the 3D model of the extracted facade using the images previously segmented in the 2D domain by the technique of \emph{Ray-Tracing}.    
\end{enumerate}

\subsection{Thesis's structure}
Based on this workflow, in Section \ref{chapter2} it is highlighted the essential urban characteristics for the extraction of information through remote sensing, its challenges and the evolution of techniques. In Section \ref{chapter3}, the details of the methodology and data adopted for the study are presented. In Section \ref{chapter4}, it is analyzed the results in both categories: on 2-dimension (quality of detection) and 3-dimension (quality of 3D labeling), as well as the training effects between the architectural style and the inference quality under an unknown one. Finally, in Section \ref{chapter5}, our main conclusions and future prospects.
